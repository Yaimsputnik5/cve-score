#!/usr/bin/env python3

import json
import logging
import argparse
import settings
import transforms

METHODS = {
    'flatten': transforms.flatten,
    'tokenize': transforms.tokenize,
}

def _walk_object(data, keys):
    if not keys:
        return data
    elif isinstance(data, dict):
        child = data.get(keys[0], {})
        return _walk_object(child, keys[1:])
    else:
        raise Exception('path mismatch %s: %s' % (keys, data))

def do_task(data, path, method):
    '''Performs a single preprocessing task.

    Arguments:
        data:   [dict] deserialized JSON object.
        path:   [str] dot-separated path to target value.
        method: [str] name of method to apply to target value.

    Returns: (<name>, <result>) pair, or `None` on error.
    '''
    target = _walk_object(data, path.split('.'))
    return ('%s.%s' % (path, method), METHODS[method](target))

def emitter(filename, tasks):
    '''Iterator returning all transformed records.

    Arguments:
        filename:   [str] file with one JSON record per line
        tasks:      [list] of dask definitions
    '''
    for record in map(json.loads, open(filename)):
        try:
            yield dict([do_task(record, **task) for task in tasks])
        except Exception as ex:
            logging.warn('%s => %s', record, ex)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('infile', help='one JSON record per line')
    parser.add_argument('tasks', help='JSON file of task definitions')
    parser.add_argument('outfile')
    parser.add_argument('--logging', help='JSON file for basicConfig')
    args = parser.parse_args()

    settings.configure_logging(args.logging)
    tasks = json.load(open(args.tasks))
    with open(args.outfile, 'w') as fh:
        logging.info('writing %s', args.outfile)
        for record in emitter(args.infile, tasks):
            fh.write('%s\n' % json.dumps(record))
