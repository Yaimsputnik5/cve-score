#!/usr/bin/env python3

import argparse
import logging
import shutil
import json

import numpy as np
import tensorflow as tf

from adaptor import JSONAdaptor
from settings import configure_logging

LOGGER = logging.getLogger('cve-score')

BUFFER_SIZE = 10000


def get_iterator(source, batch_size, shuffle=False):
    '''Returns a tf.data.Iterator for one epoch.

    Arguments:
        source      [class] `adaptor` object with generator property.
        batch_size  [int] batch size per step.
        shuffle     [bool] Randomize the order of examples.
    '''
    ds = tf.data.Dataset.from_generator(
        source.generator, source.types, source.shapes)

    if shuffle:
        ds = ds.shuffle(BUFFER_SIZE)

    ds = ds.batch(batch_size)
    iter_ = ds.make_one_shot_iterator()
    return iter_.get_next()


def write_probabilities(predictions, class_labels):
    '''Creates a CSV file of `(prob=0, prob=1, label)` records.

    Arguments:
        predictions:  iterable of `tf.estimator.Estimator.predict` records.
        class_labels: iterable of true labels.
    '''
    import csv
    probabilities = [item['probabilities'] for item in predictions]
    
    LOGGER.info('writing to %s', FLAGS.predictions)
    with open(FLAGS.predictions, 'w') as fh:
        writer = csv.writer(fh)
        writer.writerow(['prob=0', 'prob=1', 'label'])
        for probs, label in zip(probabilities, class_labels):
            writer.writerow(list(probs) + [label])


def main(_):
    shutil.rmtree(FLAGS.model_dir, ignore_errors=True)

    with open(FLAGS.config) as fh:
        config = json.load(fh)

    training = JSONAdaptor(config, FLAGS.train)
    validation = JSONAdaptor(config, FLAGS.eval)

    estimator = tf.estimator.LinearClassifier(
        feature_columns=training.columns,
        model_dir=FLAGS.model_dir,
        optimizer=tf.train.FtrlOptimizer(FLAGS.learning_rate))

    for epoch in range(FLAGS.num_epochs):
        estimator.train(
            lambda: get_iterator(training, FLAGS.batch_size, True))
        _ = estimator.evaluate(
            lambda: get_iterator(validation, FLAGS.batch_size))

    if FLAGS.predictions:
        predictions = estimator.predict(
            lambda: get_iterator(validation, FLAGS.batch_size),
            predict_keys='probabilities')

        class_labels = [label for (_, label) in validation.generator()]
        write_probabilities(predictions, class_labels)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('config', help='JSON config for pasing examples')
    parser.add_argument('train', help='JSONL training examples')
    parser.add_argument('eval', help='JSONL validation examples')
    parser.add_argument('--predictions', help='CSV file of predicted probs')
    parser.add_argument('--model-dir', default='/tmp/cve-softmax')
    parser.add_argument('--num-epochs', type=int, default=10)
    parser.add_argument('--batch-size', type=int, default=64)
    parser.add_argument('--learning-rate', type=float, default=1e-2)
    parser.add_argument('--pos-rate', type=float, default=1e-1,
        help='positive class prior probability')
    FLAGS = parser.parse_args()
    configure_logging()

    tf.app.run()
