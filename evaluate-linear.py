#!/usr/bin/env python3

import argparse
import logging
import shutil
import json

import numpy as np
import tensorflow as tf

from adaptor import JSONAdaptor
from settings import configure_logging

LOGGER = logging.getLogger('cve-score')

BUFFER_SIZE = 10000


def get_iterator(source, batch_size, shuffle=False):
    '''Returns a tf.data.Iterator for one epoch.

    Arguments:
        source      [class] `adaptor` object with generator property.
        batch_size  [int] batch size per step.
        shuffle     [bool] Randomize the order of examples.
    '''
    ds = tf.data.Dataset.from_generator(
        source.generator, source.types, source.shapes)

    if shuffle:
        ds = ds.shuffle(BUFFER_SIZE)

    ds = ds.batch(batch_size)
    iter_ = ds.make_one_shot_iterator()
    return iter_.get_next()


def model_fn(features, labels, mode):
    '''For the target Estimator.'''

    logits = tf.layers.dense(
        features, units=2,
        kernel_initializer=tf.truncated_normal_initializer(),
        name='dense')

    predictions = {
        'classes': tf.argmax(input=logits, axis=1),
        'probs': tf.nn.softmax(logits, name='softmax_tensor')
    }

    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

    onehot_labels = tf.one_hot(labels, depth=2)
    weights = tf.ones(tf.shape(labels))
    weights += tf.cast(labels, tf.float32) / FLAGS.pos_rate

    loss = tf.losses.softmax_cross_entropy(
        onehot_labels, logits, weights=weights)

    if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = tf.train.AdagradOptimizer(
            learning_rate=FLAGS.learning_rate)
        train_op = optimizer.minimize(
            loss=loss,
            global_step=tf.train.get_global_step())
        return tf.estimator.EstimatorSpec(
            mode=mode, loss=loss, train_op=train_op)

    eval_metric_ops = {
        'accuracy': tf.metrics.accuracy(
            labels=labels, predictions=predictions['classes']),
        'precision': tf.metrics.precision(
            labels=labels, predictions=predictions['classes']),
        'recall': tf.metrics.recall(
            labels=labels, predictions=predictions['classes']),
    }
    return tf.estimator.EstimatorSpec(
        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)


def main(_):
    shutil.rmtree(FLAGS.model_dir, ignore_errors=True)

    with open(FLAGS.config) as fh:
        config = json.load(fh)

    training = JSONAdaptor(config, FLAGS.train)
    validation = JSONAdaptor(config, FLAGS.eval)

    estimator = tf.estimator.Estimator(
        model_fn=model_fn,
        model_dir=FLAGS.model_dir)

    for epoch in range(FLAGS.num_epochs):

        estimator.train(
            lambda: get_iterator(training, FLAGS.batch_size, True))

        results = estimator.evaluate(
            lambda: get_iterator(validation, FLAGS.batch_size))


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('config', help='JSON config for pasing examples')
    parser.add_argument('train', help='JSONL training examples')
    parser.add_argument('eval', help='JSONL validation examples')
    parser.add_argument('--model-dir', default='/tmp/cve-softmax')
    parser.add_argument('--num-epochs', type=int, default=10)
    parser.add_argument('--batch-size', type=int, default=64)
    parser.add_argument('--learning-rate', type=float, default=1e-2)
    parser.add_argument('--pos-rate', type=float, default=1e-1,
        help='positive class prior probability')
    FLAGS = parser.parse_args()
    configure_logging()

    tf.app.run()
