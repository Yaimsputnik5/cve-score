#!/usr/bin/env python3

import re
import json
import logging
import argparse
import settings
import core.transform as xform

_text_field = 'summary'
_tokenizer = xform.compose(
    xform.strip_stopwords, xform.strip_punctuation, str.lower
)

def get_tokens(text):
    return list(filter(None, map(_tokenizer, re.split('\s+', text))))

def get_ngrams(tokens, N):
    '''Produces N-grams from a list of (string) tokens, where the resulting
    values are concatenations of the input strings, whitespace delimited.
    For instance, 2-grams:

        ['foo', 'bar', 'baz'] => ['foo bar', 'bar baz']
    '''
    max_index = len(tokens) - N
    return [' '.join(tokens[i:i+N]) for i in range(max_index)]

def get_engineered(record):
    '''Returns a document of "engineered" features from the input record.'''
    tokens = get_tokens(record.get(_text_field, ''))
    return {
        'tokens': tokens,
        'bigrams': get_ngrams(tokens, 2)
    }


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('infile', help='one JSON record per line')
    parser.add_argument('outfile', help='one JSON record per line')
    parser.add_argument('--logging', help='path to JSON config')
    args = parser.parse_args()
    settings.configure_logging(args.logging)

    with open(args.outfile, 'w') as f_out:
        logging.info('writing to %s', args.outfile)
        for record in map(json.loads, open(args.infile)):
            engineered = record.setdefault('engineered', {})
            features = get_engineered(record)
            engineered.update(features)
            f_out.write('%s\n' % json.dumps(record))
