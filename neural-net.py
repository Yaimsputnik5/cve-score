#!/usr/bin/env python3

import click
import json
import logging

from collections import Counter
from tensorflow.keras import layers, optimizers
from tensorflow.keras import Model
from tensorflow.keras.models import load_model

from common import deserialize, load_json, write_csv
from common import to_keras_format
import settings

LOGGER = logging.getLogger('cve-score')


def class_weights(labels):
    '''Like the `sklearn.utils.class_weight` but infers the labels.'''
    n_samples, counts = labels.shape[0], Counter(labels)
    return {
        label: n_samples / 2 / count for (label, count) in counts.items()
    }


def _stack_dense(input_layer, config, key):
    last_layer = input_layer
    layer_cfgs = config.get(key, [])
    LOGGER.info('building layers "%s": %s', key, json.dumps(layer_cfgs))
    for cfg in layer_cfgs:
        last_layer = layers.Dense(**cfg)(last_layer)
    return last_layer


def build_model(feature_cols, config, learning_rate):
    '''Returns a keras.Model.'''
    input_mapping = {
        key: layers.Input(shape=(tensor.shape[-1],), name=key)
        for (key, tensor) in feature_cols.items()
    }
    hidden_layers = [
        _stack_dense(tensor, config.get('hidden_layers', {}), key)
        for (key, tensor) in input_mapping.items()
    ]
    output_layer = (hidden_layers[0] if len(hidden_layers) == 1
        else layers.concatenate(hidden_layers))
    if 'dropout_layer' in config:
        output_layer = layers.Dropout(**config['dropout_layer'])(output_layer)
    output_layer = _stack_dense(output_layer, config, 'output_layers')
    model = Model(inputs=list(input_mapping.values()), outputs=output_layer)
    optimizer = optimizers.Adam(lr=learning_rate)
    model.compile(loss='binary_crossentropy', optimizer=optimizer)
    return model


@click.group()
def cli():
    pass


@cli.command()
@click.argument('config')
@click.argument('dataset')
@click.argument('model')
@click.option('--features', '-x', multiple=True, required=True,
    help='key names of feature columns in DATASET')
@click.option('--label', '-y', required=True,
    help='key name of label column in DATASET')
@click.option('--learning-rate', '-l',
    type=float, default=1e-3, show_default=True)
@click.option('--batch-size', type=int, default=32, show_default=True)
@click.option('--epochs', type=int, default=10, show_default=True)
@click.option('--validation-split',
    type=float, default=0.25, show_default=True)
def train(config, dataset, model, features, label, learning_rate,
        batch_size, epochs, validation_split):
    '''Trains a Keras model against the serialized data.

    The DATASET should be a serialized dictionary of NumPy tensors.
    The CONFIG object is JSON file specifying the basic architecture of
    (dense) layers. The emitted MODEL is serialized in H5 format.
    '''
    config = load_json(config)
    data = deserialize(dataset)
    feature_cols, label_col = to_keras_format(data, features, label)
    estimator = build_model(feature_cols, config, learning_rate)
    params = dict(batch_size=batch_size,
        epochs=epochs,
        validation_split=validation_split,
        class_weight=class_weights(label_col))
    history = estimator.fit(feature_cols, label_col, **params)
    LOGGER.info('history => %s', json.dumps(history.history))
    LOGGER.info('serializing %s', model)
    estimator.save(model)


@cli.command()
@click.argument('model')
@click.argument('dataset')
@click.argument('outfile')
@click.option('--label', '-y', help='key name of label column in DATASET')
def eval(dataset, model, outfile, label):
    '''Performs inference of a trained model against the dataset.

    Returns a CSV file with the column "p_hat" of prediction scores.
    If the LABEL is provided and present in DATASET, this column is also
    included as "y_true" in the emitted artifact.
    '''
    LOGGER.info('deserializing %s', model)
    estimator = load_model(model)
    model_cfg = estimator.get_config()
    features = [layer[0] for layer in model_cfg['input_layers']]
    data = deserialize(dataset)
    feature_cols, label_col = to_keras_format(data, features, label)
    p_hat = estimator.predict(feature_cols)
    write_csv(outfile,
        p_hat=p_hat.reshape((p_hat.shape[0],)),
        y_true=label_col)


if __name__ == '__main__':
    settings.configure_logging()
    cli()
