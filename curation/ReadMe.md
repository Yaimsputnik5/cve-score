## NVD and Exploit DB data

Scripts here illustrate the workflow of using JSONL files assemble software
vulnerability datasets for supervised learning. Two sources used are the
[NVD](https://nvd.nist.gov/), which comprises the features, and
[Exploit DB](https://www.exploit-db.com/), which is used to assign positive
labels.

### Step 1. Collect and clean raw features

The script fetch-nvd.sh pulls compressed JSON files from the NVD repository
and unpacks these as a single file of JSON records. It takes a destination
path prefix as an optional argument, which defaults to $HOME/nvd-data if none
is provided.

    $ ./fetch-nvd.sh
    $ wc -l ~/nvd-data/nvd-records.jsonl
       89440 /Users/.../nvd-records.jsonl

Inspecting the few records of the file with jq reveals how deeply nested
each record is:

    $ head ~/nvd-data/nvd-records.jsonl | jq .

We use jq to prune and flatten this into a more digestible format. The
query in [prune-nvd.js](filters/prune-nvd.js) filters on only records that
have complete CVSSv2 components, and keeps three main fields:

    $ cat ~/nvd-data/nvd-records.jsonl \
        | jq  -c "$(cat filters/prune-nvd.js)" > ~/nvd-data/nvd-pruned.jsonl
    $ head ~/nvd-data/nvd-pruned.jsonl | jq .


### Step 2. Collect and clean raw labels

Exploit DB maintains a version of the database as a simple file tree index
that is synced as a GitHub repository. To extract labels from entries, a
script is provided which (naively) associates exploits to CVEs by string
matching on files:

    $ git clone https://github.com/offensive-security/exploit-database.git ~/nvd-data/exploit-db
    $ ./parse-cve.py ~/nvd-data/exploit-db.jsonl --exploit-db ~/nvd-data/exploit-db

The `--exploit-db` argument should point to the local path prefix of the
Exploit DB repository, and parsing logic appropriate to the expected file
structure is applied, associating CVE IDs to a list of exploits in which
they occur:

    $ head ~/nvd-data/exploit-db.jsonl |jq .

### Step 3. Merge the features and labels

The merge.py script is similar to the Linux join utility, except that
it operates on JSONL files and joins on a key name instead of a fixed column:

    $ ./merge-json.py ~/nvd-data/nvd-pruned.jsonl ~/nvd-data/exploit-db.jsonl \
        ~/nvd-data/nvd-edb-merged.jsonl --keyname cveid

The first and second arguments are expected to be files of JSON records,
and all records have a common property specified by the `--keyname` argument.
The result is effectively a "left outer join," were records from the second
file are merge into those from the first file (via Python's `dict.update`
method) for any pair where the attributes of their "keyname" properties
coincide.

### Class imbalance

From the files generated so far:

    $ wc -l ~/nvd-data/*.jsonl
        2150 /Users/.../exploit-db.jsonl
       89205 /Users/.../nvd-edb-merged.jsonl
       89205 /Users/.../nvd-pruned.jsonl
       89440 /Users/.../nvd-records.jsonl

The set of pruned items is slightly smaller than the raw set, since the
records with missing CVSS data were removed. All records from the pruned set
are present in the merged set, as per the point that merge-json.py performs
a left outer join.

The presence of an "exploitdb" key in a JSON record represents a training
example with a positive label. Filtering the records with jq gives a quick
insight into the class imbalance:

    $ cat ~/nvd-data/nvd-edb-merged.jsonl |jq 'has("exploitdb")' |sort |uniq -c
    87782 false
     1869 true

That is, a positive class rate of 0.021.
